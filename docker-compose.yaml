version: '3.8'

x-airflow-common: &airflow-common
  # Using build: . ensures your requirements (duckdb, pandas, boto3) 
  # are pre-installed in the image
  build: .
  environment: &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: SequentialExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: sqlite:////opt/airflow/airflow.db
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW_UID: 50000
  volumes:
    # Matches your screenshot structure
    - ./airflow_home_dev/dags:/opt/airflow/dags
    - ./airflow_home_dev:/opt/airflow/airflow_home_dev
    - ./plugins:/opt/airflow/plugins
    # File-based mount for the metadata DB
    - ./airflow.db:/opt/airflow/airflow.db
  user: "${AIRFLOW_UID:-50000}:0"

services:
  minio:
    image: minio/minio:latest
    container_name: minio-server
    ports: ["9000:9000", "9001:9001"]
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: password

  metabase:
    image: metabase/metabase:latest
    container_name: metabase-project
    ports: ["3002:3000"]
    volumes:
      - ./airflow_home_dev:/metabase-data
    depends_on: [minio]

  airflow-init:
    <<: *airflow-common
    container_name: airflow-init
    entrypoint: /bin/bash
    command:
      - -c
      - "airflow db init && airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com"

  airflow-standalone:
    <<: *airflow-common
    container_name: airflow-unified
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    ports: ["8089:8080"]
    command: standalone